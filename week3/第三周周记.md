# QG训练营xx组第三周周记：
2021年04月10日

## 生活随记

04月10日20点，昨天晚上学习了一些数据预处理和特征工程的手段，对考核的数据做了一个简单的处理，用随机森林跑了几次准确率一直在70左右，测试集和交上去的submission表现非常接近，感觉在这个上面还是没有什么过拟合问题的；今天起床之后就一直在研究泛型的写法，用了一个下午的时间把循环队列写完了，今晚在写链式队列的时候却一直没法正确输出队列节点的值，已经快疯掉了，感觉是指针哪里没传好，洗个澡再看看。

11日2点，终于总体上做完了两个队列，对于链式队列没有正确存储的问题果然是指针在捣乱，void指针不能简单的用p->data=data来赋值，要先用malloc为p的data开一段内存之后，用**memcpy**把data的内存复制到p的data上，这个点下午做循环队列的时候只是草草过了一下并没有想太多，这回算是理解深刻了。明天起床把两个队列的注释写一写就可以完成作业咯~

12日晚上10点，今天把随机森林的剪枝策略优化了一下，终于成功上到了0.72的准确率，接下来的工作就是继续优化特征工程，希望能继续提高分数。

13日晚上10点，今天进行了一整天的特征选择，尝试了多种特征 编码手段，可是准确率仍然上不去，不知道是哪里出了问题，明天是最后一天，希望能找到解决方案。

14日晚上10点，今天选择采用更强大的xgboost工具来进行你拟合，虽然在学习曲线上显示xgboost的准确率可以达到0.75，要更优于随机森林，但是实际提交的效果却远不如随机森林，其中的原因暂时还没能找到，不过今天终于找到了准确率较低的一个非常重要的原因就是之前总是把自认为不重要的两个id特征删除掉导致最相关的特征缺失，今天补充上之后模型的效果提升了0.05，确实要更优于之前了，果然数据是不会说谎的。

## 一周总结

1.这一周，学习使用了以决策树为基础的随机森林和xgboost梯度提升这两个集成算法；

2.学习了如何使用numpy和pandas对数据进行缺失值的填充；

3.对字符型数据使用适当的编码方法转化为硬编码或者哑变量；

4.了解了常见的特征工程方法（方差过滤、卡方过滤），学会了使用柱状图等来对特征进行分析；

5.学会了使用学习曲线、方差-偏差方法对模型进行调参；

## 存在问题

1.void指针的赋值不能简单的 = 必须用**memcpy**；

2.没能选择出最适合的特征来对模型进行拟合，导致了模型提升特别缓慢；

3.对模型的学习不足导致调参比较缓慢；

## 下周规划

1.进一步熟练特征选择方法；

2.学习一个机器学习算法；

